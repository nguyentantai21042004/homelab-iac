# Kubernetes Manifests - Kafka & Redis Stacks

## Tá»•ng Quan

ThÆ° má»¥c nÃ y chá»©a cÃ¡c Kubernetes manifests Ä‘á»ƒ deploy **Kafka** vÃ  **Redis** vÃ o báº¥t ká»³ namespace nÃ o trong K3s cluster.

### Äáº·c Äiá»ƒm

**Dynamic Namespace**: Deploy vÃ o namespace báº¥t ká»³  
**Private Only**: ClusterIP services, khÃ´ng expose ra ngoÃ i  
**High Availability**: Multi-replica vá»›i auto-failover  
**Persistent Storage**: DÃ¹ng Longhorn volumes  
**Production Ready**: Best practices configuration  
**Easy to Use**: Deploy scripts included

---

## Cáº¥u TrÃºc

```
k8s-manifests/
â”œâ”€â”€ kafka/                    # Kafka + Zookeeper stack
â”‚   â”œâ”€â”€ 00-namespace.yaml
â”‚   â”œâ”€â”€ 01-zookeeper-service.yaml
â”‚   â”œâ”€â”€ 02-zookeeper-statefulset.yaml
â”‚   â”œâ”€â”€ 03-kafka-service.yaml
â”‚   â”œâ”€â”€ 04-kafka-statefulset.yaml
â”‚   â”œâ”€â”€ deploy.sh
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ redis/                    # Redis + Sentinel stack
â”‚   â”œâ”€â”€ 00-namespace.yaml
â”‚   â”œâ”€â”€ 01-configmap.yaml
â”‚   â”œâ”€â”€ 02-redis-service.yaml
â”‚   â”œâ”€â”€ 03-redis-statefulset.yaml
â”‚   â”œâ”€â”€ 04-sentinel-statefulset.yaml
â”‚   â”œâ”€â”€ deploy.sh
â”‚   â””â”€â”€ README.md
â”‚
â””â”€â”€ README.md                 # This file
```

---

## Use Cases

### Kafka Stack

**Khi nÃ o dÃ¹ng:**

- Event-driven architecture
- Microservices communication
- Log aggregation
- Real-time data streaming
- Message queue vá»›i high throughput

**VÃ­ dá»¥:**

- User events tracking
- Order processing pipeline
- Log collection tá»« nhiá»u services
- Real-time analytics

### Redis Stack

**Khi nÃ o dÃ¹ng:**

- Caching layer
- Session storage
- Rate limiting
- Real-time leaderboards
- Pub/Sub messaging
- Temporary data storage

**VÃ­ dá»¥:**

- Cache API responses
- Store user sessions
- Rate limit API requests
- Real-time notifications
- Shopping cart data

---

## Quick Start

### Deploy Kafka

```bash
cd kafka
./deploy.sh my-app-kafka

# Hoáº·c deploy vÃ o namespace máº·c Ä‘á»‹nh "kafka"
./deploy.sh
```

### Deploy Redis

```bash
cd redis
./deploy.sh my-app-redis

# Hoáº·c deploy vÃ o namespace máº·c Ä‘á»‹nh "redis"
./deploy.sh
```

### Deploy Cáº£ 2 VÃ o CÃ¹ng Namespace

```bash
# Deploy Kafka
cd kafka
sed "s/NAMESPACE_NAME/my-app/g" *.yaml | kubectl apply -f -

# Deploy Redis
cd ../redis
sed "s/NAMESPACE_NAME/my-app/g" *.yaml | kubectl apply -f -
```

---

## So SÃ¡nh Kafka vs Redis

| Feature            | Kafka                         | Redis                      |
| ------------------ | ----------------------------- | -------------------------- |
| **Type**           | Message Broker / Event Stream | In-Memory Database / Cache |
| **Persistence**    | Disk-based (durable)          | Memory + Disk (optional)   |
| **Throughput**     | Very High (millions/sec)      | Extremely High (sub-ms)    |
| **Use Case**       | Event streaming, Logs         | Cache, Sessions, Counters  |
| **Data Retention** | Long-term (days/weeks)        | Short-term (seconds/hours) |
| **Message Order**  | Guaranteed (per partition)    | Not guaranteed (Pub/Sub)   |
| **Replication**    | Multi-replica                 | Master-Replica + Sentinel  |
| **Query**          | Sequential read               | Key-value lookup           |

---

## Architecture Overview

### Kafka Stack

```
Applications
    â†“
kafka-client.namespace.svc.cluster.local:9092
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Kafka Cluster (3 brokers)     â”‚
â”‚  â”œâ”€ kafka-0 (Leader)            â”‚
â”‚  â”œâ”€ kafka-1 (Follower)          â”‚
â”‚  â””â”€ kafka-2 (Follower)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Zookeeper Cluster (3 nodes)   â”‚
â”‚  â”œâ”€ zookeeper-0                 â”‚
â”‚  â”œâ”€ zookeeper-1                 â”‚
â”‚  â””â”€ zookeeper-2                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Redis Stack

```
Applications
    â†“
redis-client.namespace.svc.cluster.local:6379
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Redis Cluster                  â”‚
â”‚  â”œâ”€ redis-0 (Master)            â”‚
â”‚  â”œâ”€ redis-1 (Replica)           â”‚
â”‚  â””â”€ redis-2 (Replica)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“ monitored by
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Sentinel Cluster (3 nodes)    â”‚
â”‚  â”œâ”€ sentinel-0                  â”‚
â”‚  â”œâ”€ sentinel-1                  â”‚
â”‚  â””â”€ sentinel-2                  â”‚
â”‚  Auto-failover on master down   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Connection Examples

### Kafka Connection

**From same namespace:**

```
kafka-client:9092
```

**From different namespace:**

```
kafka-client.my-app-kafka.svc.cluster.local:9092
```

**Spring Boot:**

```yaml
spring:
  kafka:
    bootstrap-servers: kafka-client.my-app-kafka.svc.cluster.local:9092
```

### Redis Connection

**From same namespace:**

```
redis-client:6379
```

**From different namespace:**

```
redis-client.my-app-redis.svc.cluster.local:6379
```

**Spring Boot:**

```yaml
spring:
  redis:
    host: redis-client.my-app-redis.svc.cluster.local
    port: 6379
```

---

## Resource Requirements

### Kafka Stack

| Component | Replicas   | CPU (req/limit)   | Memory (req/limit) | Storage   |
| --------- | ---------- | ----------------- | ------------------ | --------- |
| Zookeeper | 3          | 100m / 500m       | 256Mi / 512Mi      | 5Gi + 2Gi |
| Kafka     | 3          | 250m / 1000m      | 512Mi / 2Gi        | 10Gi      |
| **Total** | **6 pods** | **1050m / 4500m** | **2.25Gi / 7.5Gi** | **51Gi**  |

### Redis Stack

| Component | Replicas   | CPU (req/limit)  | Memory (req/limit)   | Storage  |
| --------- | ---------- | ---------------- | -------------------- | -------- |
| Redis     | 3          | 100m / 500m      | 256Mi / 512Mi        | 5Gi      |
| Sentinel  | 3          | 50m / 200m       | 128Mi / 256Mi        | -        |
| **Total** | **6 pods** | **450m / 2100m** | **1.125Gi / 2.25Gi** | **15Gi** |

### Combined (Kafka + Redis)

- **Total Pods**: 12
- **Total CPU**: 1500m request / 6600m limit
- **Total Memory**: 3.375Gi request / 9.75Gi limit
- **Total Storage**: 66Gi

---

## Monitoring & Health Checks

### Check All Stacks

```bash
# List all namespaces with Kafka/Redis
kubectl get ns -l app.kubernetes.io/component=messaging
kubectl get ns -l app.kubernetes.io/component=cache

# Check all pods
kubectl get pods -A | grep -E "kafka|redis|zookeeper|sentinel"

# Check all PVCs
kubectl get pvc -A | grep -E "kafka|redis|zookeeper"
```

### Health Check Commands

**Kafka:**

```bash
kubectl exec -it kafka-0 -n <namespace> -- \
  kafka-topics --bootstrap-server localhost:9092 --list
```

**Redis:**

```bash
kubectl exec -it redis-0 -n <namespace> -- \
  redis-cli ping
```

---

## Cleanup

### XÃ³a Má»™t Stack

```bash
# XÃ³a Kafka
kubectl delete namespace my-app-kafka

# XÃ³a Redis
kubectl delete namespace my-app-redis
```

### XÃ³a Táº¥t Cáº£ Stacks

```bash
# XÃ³a táº¥t cáº£ namespaces cÃ³ label
kubectl delete ns -l app.kubernetes.io/component=messaging
kubectl delete ns -l app.kubernetes.io/component=cache
```

---

## Customization

### Thay Äá»•i Resource Limits

Edit StatefulSet files:

```yaml
resources:
  requests:
    cpu: 500m # TÄƒng CPU
    memory: 1Gi # TÄƒng Memory
  limits:
    cpu: 2000m
    memory: 4Gi
```

### Thay Äá»•i Storage Size

Edit volumeClaimTemplates:

```yaml
volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      resources:
        requests:
          storage: 20Gi # TÄƒng storage
```

### Thay Äá»•i Replicas

Edit StatefulSet:

```yaml
spec:
  replicas: 5 # TÄƒng sá»‘ replicas
```

---

## Security Best Practices

### 1. Network Policies

Táº¡o NetworkPolicy Ä‘á»ƒ restrict traffic:

```yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: kafka-network-policy
  namespace: my-app-kafka
spec:
  podSelector:
    matchLabels:
      app: kafka
  policyTypes:
    - Ingress
  ingress:
    - from:
        - namespaceSelector:
            matchLabels:
              name: my-app
```

### 2. Resource Quotas

Giá»›i háº¡n resources per namespace:

```yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  name: kafka-quota
  namespace: my-app-kafka
spec:
  hard:
    requests.cpu: "2"
    requests.memory: 4Gi
    persistentvolumeclaims: "10"
```

### 3. Pod Security

Enable Pod Security Standards:

```yaml
apiVersion: v1
kind: Namespace
metadata:
  name: my-app-kafka
  labels:
    pod-security.kubernetes.io/enforce: restricted
```

---

## Documentation

- [Kafka Stack README](kafka/README.md) - Chi tiáº¿t vá» Kafka deployment
- [Redis Stack README](redis/README.md) - Chi tiáº¿t vá» Redis deployment

---

## Notes

- **Namespace Isolation**: Má»—i application nÃªn cÃ³ namespace riÃªng
- **Private Only**: Services chá»‰ accessible trong cluster
- **Persistent Data**: Data Ä‘Æ°á»£c lÆ°u trong Longhorn volumes
- **High Availability**: Multi-replica vá»›i auto-failover
- **Production Ready**: ÄÃ£ config best practices

---

**Version:** 1.0  
**Last Updated:** 2026-02-08  
**Maintained by:** Homelab Infrastructure Team

# Resource Planning & Configuration Guide

## ğŸ“Š Tá»•ng Quan Resource Consumption

Báº£ng nÃ y giÃºp báº¡n tÃ­nh toÃ¡n tÃ i nguyÃªn cáº§n thiáº¿t cho K3s cluster.

---

## ğŸ¯ Resource Summary Table

### Redis Stack (High Availability Mode)

| Component    | Replicas | CPU Request | CPU Limit | Memory Request | Memory Limit | Storage | Total CPU | Total Memory | Total Storage |
| ------------ | -------- | ----------- | --------- | -------------- | ------------ | ------- | --------- | ------------ | ------------- |
| **Redis**    | 3        | 100m        | 500m      | 256Mi          | 512Mi        | 5Gi     | 300m      | 768Mi        | 15Gi          |
| **Sentinel** | 3        | 50m         | 200m      | 128Mi          | 256Mi        | -       | 150m      | 384Mi        | -             |
| **TOTAL**    | 6 pods   | -           | -         | -              | -            | -       | **450m**  | **1.15Gi**   | **15Gi**      |

### Kafka Stack (High Availability Mode)

| Component     | Replicas | CPU Request | CPU Limit | Memory Request | Memory Limit | Storage   | Total CPU | Total Memory | Total Storage |
| ------------- | -------- | ----------- | --------- | -------------- | ------------ | --------- | --------- | ------------ | ------------- |
| **Kafka**     | 3        | 250m        | 1000m     | 512Mi          | 2Gi          | 10Gi      | 750m      | 1.5Gi        | 30Gi          |
| **Zookeeper** | 3        | 100m        | 500m      | 256Mi          | 512Mi        | 5Gi + 2Gi | 300m      | 768Mi        | 21Gi          |
| **TOTAL**     | 6 pods   | -           | -         | -              | -            | -         | **1050m** | **2.27Gi**   | **51Gi**      |

### n8n Stack (Single Mode)

| Component | Replicas | CPU Request | CPU Limit | Memory Request | Memory Limit | Storage | Total CPU | Total Memory | Total Storage |
| --------- | -------- | ----------- | --------- | -------------- | ------------ | ------- | --------- | ------------ | ------------- |
| **n8n**   | 1        | 100m        | 1000m     | 256Mi          | 1Gi          | 10Gi    | 100m      | 256Mi        | 10Gi          |
| **TOTAL** | 1 pod    | -           | -         | -              | -            | -       | **100m**  | **256Mi**    | **10Gi**      |

### n8n Stack (Queue Mode - vá»›i Redis)

| Component    | Replicas | CPU Request | CPU Limit | Memory Request | Memory Limit | Storage | Total CPU | Total Memory | Total Storage |
| ------------ | -------- | ----------- | --------- | -------------- | ------------ | ------- | --------- | ------------ | ------------- |
| **n8n**      | 3        | 100m        | 1000m     | 256Mi          | 1Gi          | 10Gi    | 300m      | 768Mi        | 30Gi          |
| **Redis**    | 3        | 100m        | 500m      | 256Mi          | 512Mi        | 5Gi     | 300m      | 768Mi        | 15Gi          |
| **Sentinel** | 3        | 50m         | 200m      | 128Mi          | 256Mi        | -       | 150m      | 384Mi        | -             |
| **TOTAL**    | 9 pods   | -           | -         | -              | -            | -       | **750m**  | **1.92Gi**   | **45Gi**      |

---

## ğŸ–¥ï¸ Cluster Sizing Recommendations

### Minimum Cluster (Development/Testing)

**Scenario:** n8n (single) + Redis (HA)

```
Total Resources:
- CPU Request: 550m (0.55 cores)
- Memory Request: 1.4Gi
- Storage: 25Gi

Recommended K3s Nodes:
- 2 nodes x (2 CPU, 4GB RAM, 50GB disk)
- Total: 4 CPU, 8GB RAM, 100GB disk
```

### Medium Cluster (Production - Light Load)

**Scenario:** n8n (single) + Redis (HA) + Kafka (HA)

```
Total Resources:
- CPU Request: 1600m (1.6 cores)
- Memory Request: 3.67Gi
- Storage: 76Gi

Recommended K3s Nodes:
- 3 nodes x (2 CPU, 6GB RAM, 100GB disk)
- Total: 6 CPU, 18GB RAM, 300GB disk
```

### Large Cluster (Production - Heavy Load)

**Scenario:** n8n (queue mode) + Redis (HA) + Kafka (HA)

```
Total Resources:
- CPU Request: 1800m (1.8 cores)
- Memory Request: 4.19Gi
- Storage: 96Gi

Recommended K3s Nodes:
- 3 nodes x (4 CPU, 8GB RAM, 150GB disk)
- Total: 12 CPU, 24GB RAM, 450GB disk
```

---

## âš™ï¸ Configuration Profiles

### Profile 1: Minimal (Homelab/Testing)

**Use case:** Há»c táº­p, testing, demo

**Redis:**

```yaml
resources:
  requests:
    cpu: 50m
    memory: 128Mi
  limits:
    cpu: 250m
    memory: 256Mi
storage: 2Gi
replicas: 1 # Single instance, no HA
```

**Kafka:**

```yaml
resources:
  requests:
    cpu: 100m
    memory: 256Mi
  limits:
    cpu: 500m
    memory: 1Gi
storage: 5Gi
replicas: 1 # Single broker
```

**n8n:**

```yaml
resources:
  requests:
    cpu: 50m
    memory: 128Mi
  limits:
    cpu: 500m
    memory: 512Mi
storage: 5Gi
replicas: 1
```

**Total:** ~200m CPU, ~512Mi RAM, ~12Gi storage

---

### Profile 2: Standard (Production - Light)

**Use case:** Äá»“ Ã¡n, small business, personal projects

**Redis:** (Giá»¯ nguyÃªn nhÆ° manifest hiá»‡n táº¡i)

```yaml
resources:
  requests:
    cpu: 100m
    memory: 256Mi
  limits:
    cpu: 500m
    memory: 512Mi
storage: 5Gi
replicas: 3 # HA mode
```

**Kafka:** (Giá»¯ nguyÃªn)

```yaml
resources:
  requests:
    cpu: 250m
    memory: 512Mi
  limits:
    cpu: 1000m
    memory: 2Gi
storage: 10Gi
replicas: 3
```

**n8n:** (Giá»¯ nguyÃªn)

```yaml
resources:
  requests:
    cpu: 100m
    memory: 256Mi
  limits:
    cpu: 1000m
    memory: 1Gi
storage: 10Gi
replicas: 1
```

---

### Profile 3: Performance (Production - Heavy)

**Use case:** High traffic, nhiá»u workflows, real-time processing

**Redis:**

```yaml
resources:
  requests:
    cpu: 200m
    memory: 512Mi
  limits:
    cpu: 1000m
    memory: 1Gi
storage: 10Gi
replicas: 3
```

**Kafka:**

```yaml
resources:
  requests:
    cpu: 500m
    memory: 1Gi
  limits:
    cpu: 2000m
    memory: 4Gi
storage: 50Gi
replicas: 3
```

**n8n:**

```yaml
resources:
  requests:
    cpu: 500m
    memory: 1Gi
  limits:
    cpu: 2000m
    memory: 4Gi
storage: 20Gi
replicas: 3 # Queue mode vá»›i Redis
```

**Total:** ~3.6 cores CPU, ~7.5Gi RAM, ~180Gi storage

---

## ğŸ”§ CÃ¡ch Thay Äá»•i Resource Configuration

### Method 1: Edit YAML trÆ°á»›c khi deploy

**VÃ­ dá»¥: Giáº£m resource cho Redis (Minimal profile)**

Edit `k8s-manifests/redis/03-redis-statefulset.yaml`:

```yaml
resources:
  requests:
    cpu: 50m # Giáº£m tá»« 100m
    memory: 128Mi # Giáº£m tá»« 256Mi
  limits:
    cpu: 250m # Giáº£m tá»« 500m
    memory: 256Mi # Giáº£m tá»« 512Mi
```

Edit storage:

```yaml
volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      resources:
        requests:
          storage: 2Gi # Giáº£m tá»« 5Gi
```

### Method 2: Patch sau khi deploy

```bash
# Patch CPU/Memory
kubectl patch statefulset redis -n redis \
  --type='json' \
  -p='[{
    "op": "replace",
    "path": "/spec/template/spec/containers/0/resources/requests/cpu",
    "value": "50m"
  }]'

# Restart pods Ä‘á»ƒ apply changes
kubectl rollout restart statefulset redis -n redis
```

### Method 3: Edit trá»±c tiáº¿p

```bash
# Edit StatefulSet
kubectl edit statefulset redis -n redis

# TÃ¬m section resources vÃ  sá»­a
# Save vÃ  exit â†’ Pods sáº½ restart tá»± Ä‘á»™ng
```

---

## ğŸ“ˆ Monitoring & Tuning

### Check Resource Usage

```bash
# Xem resource usage cá»§a pods
kubectl top pods -n redis
kubectl top pods -n kafka
kubectl top pods -n n8n

# Xem resource usage cá»§a nodes
kubectl top nodes

# Xem resource requests/limits
kubectl describe node <node-name>
```

### Identify Resource Bottlenecks

```bash
# Pods bá»‹ OOMKilled (out of memory)
kubectl get pods -A | grep OOMKilled

# Pods bá»‹ Evicted (node háº¿t tÃ i nguyÃªn)
kubectl get pods -A | grep Evicted

# Check events
kubectl get events -A --sort-by='.lastTimestamp'
```

### Tuning Guidelines

**CPU:**

- Request: Minimum CPU cáº§n Ä‘á»ƒ pod cháº¡y bÃ¬nh thÆ°á»ng
- Limit: Maximum CPU pod cÃ³ thá»ƒ dÃ¹ng (throttle náº¿u vÆ°á»£t)
- Náº¿u pod bá»‹ CPU throttle: TÄƒng limit
- Náº¿u node overcommit: TÄƒng request

**Memory:**

- Request: Minimum memory Ä‘á»ƒ schedule pod
- Limit: Maximum memory (OOMKill náº¿u vÆ°á»£t)
- Náº¿u pod bá»‹ OOMKilled: TÄƒng limit
- Náº¿u memory leak: Fix code, khÃ´ng chá»‰ tÄƒng limit

**Storage:**

- Longhorn volume cÃ³ thá»ƒ expand sau khi táº¡o
- KhÃ´ng thá»ƒ shrink (giáº£m size)

```bash
# Expand PVC
kubectl patch pvc redis-data-redis-0 -n redis \
  -p '{"spec":{"resources":{"requests":{"storage":"10Gi"}}}}'
```

---

## ğŸ¯ Recommendations cho Äá»“ Ãn

### Scenario 1: Budget Tight (1 VM, 4GB RAM)

**Chá»‰ deploy n8n + External Postgres:**

```
n8n: 1 replica (100m CPU, 256Mi RAM, 5Gi storage)
Postgres: TrÃªn VM host (khÃ´ng tÃ­nh vÃ o K3s)

Total K3s: 100m CPU, 256Mi RAM, 5Gi storage
â†’ Cháº¡y thoáº£i mÃ¡i trÃªn 1 VM 2 CPU, 4GB RAM
```

### Scenario 2: Standard (3 VMs, 6GB RAM má»—i VM)

**n8n + Redis HA:**

```
n8n: 1 replica
Redis: 3 replicas (HA)
Sentinel: 3 replicas

Total: 550m CPU, 1.4Gi RAM, 25Gi storage
â†’ Cháº¡y tá»‘t trÃªn 3 VMs x (2 CPU, 6GB RAM)
```

### Scenario 3: Full Stack (3 VMs, 8GB RAM má»—i VM)

**n8n + Redis + Kafka (táº¥t cáº£ HA):**

```
n8n: 1 replica
Redis: 3 replicas
Sentinel: 3 replicas
Kafka: 3 brokers
Zookeeper: 3 nodes

Total: 1600m CPU, 3.67Gi RAM, 76Gi storage
â†’ Cáº§n 3 VMs x (4 CPU, 8GB RAM, 100GB disk)
```

---

## ğŸ’¡ Cost Optimization Tips

### 1. Giáº£m Replicas cho Dev/Test

```yaml
# Thay vÃ¬ 3 replicas (HA)
replicas: 3

# DÃ¹ng 1 replica cho testing
replicas: 1
```

**Tiáº¿t kiá»‡m:** ~66% resources

### 2. DÃ¹ng Minimal Profile

Ãp dá»¥ng Profile 1 (Minimal) cho táº¥t cáº£ services.

**Tiáº¿t kiá»‡m:** ~50% CPU, ~50% RAM

### 3. Shared Redis

Thay vÃ¬ má»—i app cÃ³ Redis riÃªng, dÃ¹ng chung 1 Redis cluster.

```yaml
# n8n queue mode
QUEUE_BULL_REDIS_HOST: redis-client.shared-redis.svc.cluster.local

# App khÃ¡c cÅ©ng dÃ¹ng chung
```

**Tiáº¿t kiá»‡m:** KhÃ´ng cáº§n deploy nhiá»u Redis clusters

### 4. Storage Optimization

```yaml
# Giáº£m retention cho Kafka
KAFKA_LOG_RETENTION_HOURS: "24" # 1 day thay vÃ¬ 7 days

# Enable compression
KAFKA_COMPRESSION_TYPE: "gzip"
```

### 5. Disable Unused Features

```yaml
# n8n: Disable execution data náº¿u khÃ´ng cáº§n
EXECUTIONS_DATA_SAVE_ON_SUCCESS: "none"
EXECUTIONS_DATA_SAVE_ON_ERROR: "all"
```

---

## ğŸ“Š Quick Reference Table

| Profile         | Use Case          | Total CPU | Total RAM | Total Storage | Nodes           |
| --------------- | ----------------- | --------- | --------- | ------------- | --------------- |
| **Minimal**     | Testing, Demo     | 200m      | 512Mi     | 12Gi          | 1 node (2C/4G)  |
| **Standard**    | Äá»“ Ã¡n, Small Prod | 1600m     | 3.67Gi    | 76Gi          | 3 nodes (2C/6G) |
| **Performance** | Heavy Load        | 3600m     | 7.5Gi     | 180Gi         | 3 nodes (4C/8G) |

---

## ğŸ” Troubleshooting Resource Issues

### Pod Pending (Insufficient Resources)

```bash
# Check why pod pending
kubectl describe pod <pod-name> -n <namespace>

# Look for: "Insufficient cpu" or "Insufficient memory"
```

**Solution:**

1. Giáº£m resource requests
2. ThÃªm nodes vÃ o cluster
3. XÃ³a pods khÃ´ng cáº§n thiáº¿t

### Node Pressure (High Resource Usage)

```bash
# Check node conditions
kubectl describe node <node-name>

# Look for: MemoryPressure, DiskPressure
```

**Solution:**

1. Evict pods khÃ´ng quan trá»ng
2. TÄƒng node resources
3. Add more nodes

### OOMKilled (Out of Memory)

```bash
# Check pod status
kubectl get pods -A | grep OOMKilled

# Check logs before crash
kubectl logs <pod-name> -n <namespace> --previous
```

**Solution:**

1. TÄƒng memory limit
2. Fix memory leak trong app
3. Enable memory profiling

---

**Last Updated:** 2026-02-08  
**Tested on:** K3s v1.28+, Longhorn v1.5+
